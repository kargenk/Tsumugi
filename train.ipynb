{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "#!/usr/bin/env python3\n",
    "# -*- coding: utf-8 -*-"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "import spacy\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import random\n",
    "import sys\n",
    "from tensorflow.keras.layers import Dense, LSTM, Bidirectional, Dropout\n",
    "from tensorflow.keras.models import Sequential, load_model\n",
    "from tensorflow.keras.callbacks import EarlyStopping\n",
    "\n",
    "from util import remove_fullspace_and_newline, reweight_distribution, sample"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0    まるで荒れる波涛のように背筋つらぬき　心狂わす出逢いそう　出逢い夢うつつと見紛(みまご)うほ...\n",
       "1    Don't Don't Don't Stay Good-byeDon't Don't Don...\n",
       "2    YES♪広い空のようなみんな夢を見てるそして叶えてく輝くこの宇宙(そら)でどこ行(ゆ)こうM...\n",
       "3    いっしょに歌おういっしょの時代(とき)の中いっしょで行こういっしょな夢を見よういっしょにいよ...\n",
       "4    アッ！とね　言わせて見たいいっぱい愛があふれるウットリするような世界創ろうガッカリするのまだ...\n",
       "Name: Lyric, dtype: object"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# 歌詞データの読み込み\n",
    "df = pd.read_csv('./datasets/all_songs.csv')\n",
    "lyrics = df['Lyric']\n",
    "lyrics.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 前処理"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'瑠璃色金魚は恋い焦がれる凛と咲き誇る花菖蒲吐き出す空気は泡の模様決してあなたの心に届かないのはなびらひらひらと水面に落ちて震える指先時間が止まるわ目が覚めた余韻の余白外の世界はねえなんて眩しい嘘だとしても罪深過ぎたの眩暈がしても心地いいのはもう求めてるから瑠璃色金魚が見上げるのは凛と佇んだ花菖蒲私あなたのようになれたらもっと上手く微笑えますか灯した明かりは燃えないまま今も青く棚引いている曇った硝子を溶かすほどの秘密もしかして私持ってますか雨は空に落ち愛すれば消えるものと思ってた鏡の世界に逆さまに映った好奇心湧き上がる思いを掬い上げては砂糖漬けにしてまた飲み込むのあなたにいつか味見してほしいと夢を見ながら瑠璃色金魚が知らないのは強く根を張った花菖蒲目の前に見えるもの全てが現実ってことはないのあの時触れてくれた温もり光失くしては枯れていく悲しみで泣く私の涙また毒になってしまう抜け出したい瑠璃色金魚が見上げるのは凛と佇んだ花菖蒲私あなたのようになれたらもっと美しく咲き誇れますか瑠璃色金魚が知らないのは強く根を張った花菖蒲目の前に見えるもの全てが現実ってことはないのあの時触れてくれた温もり光失くしては枯れていく悲しみで泣く私の涙また毒になってしまう抜け出したい私きっと'"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# 前処理(全角スペースや改行を除去)\n",
    "removed_list = [remove_fullspace_and_newline(lyric) for lyric in lyrics]\n",
    "removed_list[-2]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 辞書の準備\n",
    "# 大量の文書を扱うときはpipeを使うと内部的にバッチ化され，効率化される\n",
    "nlp = spacy.load('ja_ginza')\n",
    "docs = list(nlp.pipe(removed_list))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['瑠璃', '色金', '魚', 'は', '恋い焦がれる', '凛と', '咲き誇る', '花菖蒲', '吐き出す', '空気', 'は', '泡', 'の', '模様', '決して', 'あなた', 'の', '心', 'に', '届か', 'ない', 'の', 'はなびら', 'ひらひら', 'と', '水面', 'に', '落ち', 'て', '震える', '指先', '時間', 'が', '止まる', 'わ', '目', 'が', '覚め', 'た', '余韻', 'の', '余白', '外', 'の', '世界', 'は', 'ねえ', 'なんて', '眩しい', '嘘', 'だ', 'と', 'し', 'て', 'も', '罪深', '過ぎ', 'た', 'の', '眩暈', 'が', 'し', 'て', 'も', '心地', 'いい', 'の', 'は', 'もう', '求め', 'てる', 'から', '瑠璃', '色金', '魚', 'が', '見上げる', 'の', 'は', '凛と', '佇ん', 'だ', '花菖蒲', '私', 'あなた', 'の', 'よう', 'に', 'なれ', 'たら', 'もっと', '上手く', '微笑え', 'ます', 'か', '灯し', 'た', '明かり', 'は', '燃え', 'ない', 'まま', '今', 'も', '青く', '棚引い', 'て', 'いる', '曇っ', 'た', '硝子', 'を', '溶かす', 'ほど', 'の', '秘密', 'もし', 'か', 'し', 'て', '私', '持っ', 'て', 'ます', 'か', '雨', 'は', '空', 'に', '落ち', '愛すれ', 'ば', '消える', 'もの', 'と', '思っ', 'て', 'た', '鏡', 'の', '世界', 'に', '逆さま', 'に', '映っ', 'た', '好奇心', '湧き上がる', '思い', 'を', '掬い上げ', 'て', 'は', '砂糖', '漬け', 'に', 'し', 'て', 'また', '飲み込む', 'の', 'あなた', 'に', 'いつ', 'か', '味見', 'し', 'て', 'ほしい', 'と', '夢', 'を', '見', 'ながら', '瑠璃', '色金', '魚', 'が', '知ら', 'ない', 'の', 'は', '強く', '根', 'を', '張っ', 'た', '花菖蒲', '目', 'の', '前', 'に', '見える', 'もの', '全て', 'が', '現実', 'って', 'こと', 'は', 'ない', 'の', 'あの', '時', '触れ', 'て', 'くれ', 'た', '温もり', '光', '失くし', 'て', 'は', '枯れ', 'て', 'いく', '悲しみ', 'で', '泣く', '私', 'の', '涙', 'また', '毒', 'に', 'なっ', 'て', 'しまう', '抜け出し', 'たい', '瑠璃', '色金', '魚', 'が', '見上げる', 'の', 'は', '凛と', '佇ん', 'だ', '花菖蒲', '私', 'あなた', 'の', 'よう', 'に', 'なれ', 'たら', 'もっと', '美しく', '咲き誇れ', 'ます', 'か', '瑠璃', '色金', '魚', 'が', '知ら', 'ない', 'の', 'は', '強く', '根', 'を', '張っ', 'た', '花菖蒲', '目', 'の', '前', 'に', '見える', 'もの', '全て', 'が', '現実', 'って', 'こと', 'は', 'ない', 'の', 'あの', '時', '触れ', 'て', 'くれ', 'た', '温もり', '光', '失くし', 'て', 'は', '枯れ', 'て', 'いく', '悲しみ', 'で', '泣く', '私', 'の', '涙', 'また', '毒', 'に', 'なっ', 'て', 'しまう', '抜け出し', 'たい', '私', 'きっと']\n"
     ]
    }
   ],
   "source": [
    "# コーパスの分かち書きの作成\n",
    "lyrics_wakati = []\n",
    "for doc in docs:\n",
    "    lyric_wakati = []\n",
    "    for word in doc:\n",
    "        lyric_wakati.append(word.text)  # 各要素はspacy.tokens.token.Tokenなので，textでstrとして抽出\n",
    "    lyrics_wakati.append(lyric_wakati)\n",
    "print(lyrics_wakati[-2], sep='\\n')      # 整形して瑠璃色金魚と花菖蒲の結果を確認"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Corpus length: 119916\n",
      "Unique words: 11362\n"
     ]
    }
   ],
   "source": [
    "# 分かち書きからコーパスの一意な単語のリストを作成\n",
    "flatten = sum(lyrics_wakati, [])   # 平坦化\n",
    "print('Corpus length:', len(flatten))\n",
    "\n",
    "words = sorted(list(set(flatten))) # set(集合)を用いて要素を一意に\n",
    "print('Unique words:', len(words))\n",
    "\n",
    "# 歌詞中の単語をリストwordsのインデックスにマッピングするディクショナリ\n",
    "word_indices = dict((word, words.index(word)) for word in words)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 入力と出力(目的値)の作成"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Number of sequences: 39971\n"
     ]
    }
   ],
   "source": [
    "maxlen = 5       # 5単語分の歌詞を抽出\n",
    "step = 3         # 3単語ごとに新しい歌詞をサンプリング\n",
    "sentences = []   # 抽出された歌詞\n",
    "next_words = []  # 目的値(次にくる単語)\n",
    "\n",
    "for i in range(0, len(flatten) - maxlen, step):\n",
    "    sentences.append(flatten[i: i + maxlen])\n",
    "    next_words.append(flatten[i + maxlen])\n",
    "\n",
    "print('Number of sequences:', len(sentences))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Vectorization...\n",
      "shape of x: (39971, 5, 11362)\n",
      "shape of y: (39971, 11362)\n"
     ]
    }
   ],
   "source": [
    "# ベクトル化(one-hotエンコーディングを適用して文字を二値の配列に格納)\n",
    "print('Vectorization...')\n",
    "\n",
    "x = np.zeros((len(sentences), maxlen, len(words)), dtype=np.bool)\n",
    "y = np.zeros((len(sentences), len(words)), dtype=np.bool)\n",
    "\n",
    "for i, sentence in enumerate(sentences):\n",
    "    for t, word in enumerate(sentence):\n",
    "        x[i, t, word_indices[word]] = 1\n",
    "    y[i, word_indices[next_words[i]]] = 1\n",
    "    \n",
    "print('shape of x:', x.shape)\n",
    "print('shape of y:', y.shape)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## モデルの構築"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "WARNING:tensorflow:From C:\\Anaconda3\\lib\\site-packages\\tensorflow\\python\\ops\\init_ops.py:1251: calling VarianceScaling.__init__ (from tensorflow.python.ops.init_ops) with dtype is deprecated and will be removed in a future version.\n",
      "Instructions for updating:\n",
      "Call initializer instance with the dtype argument instead of passing it to the constructor\n",
      "Model: \"sequential\"\n",
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "lstm (LSTM)                  (None, 128)               5883392   \n",
      "_________________________________________________________________\n",
      "dense (Dense)                (None, 11362)             1465698   \n",
      "=================================================================\n",
      "Total params: 7,349,090\n",
      "Trainable params: 7,349,090\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n"
     ]
    }
   ],
   "source": [
    "model = Sequential()\n",
    "model.add(LSTM(128, input_shape=(maxlen, len(words))))\n",
    "model.add(Dense(len(words), activation='softmax'))\n",
    "\n",
    "model.compile(loss='categorical_crossentropy',\n",
    "              optimizer='rmsprop')\n",
    "\n",
    "model.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# コールバックの設定\n",
    "def on_epoch_end(epoch, _):\n",
    "    if (epoch + 1) % 10 == 0 or epoch == 0:\n",
    "        print()"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
